{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "wav2vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "import torch\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import librosa\r\n",
        "from librosa import display\r\n",
        "from pydub import AudioSegment\r\n",
        "from pydub.silence import split_on_silence\r\n",
        "\r\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor"
      ],
      "outputs": [],
      "metadata": {
        "id": "z4t-zvTkoftL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dir = os.path.abspath(os.getcwd())\r\n",
        "path = os.path.join(dir, \"sample_audio.wav\")\r\n",
        "\r\n",
        "sample_rate = 16000\r\n",
        "\r\n",
        "audio, _ = librosa.load(path, sr = sample_rate)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SoSdHVxUoubr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure()\r\n",
        "display.waveplot(y=audio, sr=sample_rate)\r\n",
        "plt.xlabel(\"Time (seconds) ==>\")\r\n",
        "plt.ylabel(\"Amplitude\")\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "5VNpPxo9cMpq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Function to normalize given audio chunk\r\n",
        "def match_target_amplitude(aChunk, target_dBFS):\r\n",
        "  change_in_dBFS = target_dBFS - aChunk.dBFS\r\n",
        "  return aChunk.apply_gain(change_in_dBFS)\r\n",
        "\r\n",
        "\r\n",
        "# Function that splits the audio file into chunks\r\n",
        "def silence_based_conversion(path = \"sample_audio.wav\"):\r\n",
        "\r\n",
        "  audio = AudioSegment.from_wav(path)\r\n",
        "  dBFS = audio.dBFS\r\n",
        "\r\n",
        "  # split track where there is silence is\r\n",
        "  # for 0.8 seconds or more and get chunks\r\n",
        "  chunks = split_on_silence(audio,\r\n",
        "      # Specify that a silent chunk must be\r\n",
        "      # at least 0.8 seconds or 800 ms long.\r\n",
        "      min_silence_len = 800,\r\n",
        "\r\n",
        "      # consider it silent if quieter than -16 dBFS\r\n",
        "      # adjust this per requirement\r\n",
        "      silence_thresh = dBFS-16\r\n",
        "  )\r\n",
        "\r\n",
        "  # Create directory to store chunks\r\n",
        "  try:\r\n",
        "      os.mkdir('audio_chunks')\r\n",
        "  except(FileExistsError):\r\n",
        "      pass\r\n",
        "\r\n",
        "  os.chdir('audio_chunks')\r\n",
        "\r\n",
        "  # Create 0.5 seconds silence chunk\r\n",
        "  chunk_silent = AudioSegment.silent(duration = 500)\r\n",
        "  i = 0\r\n",
        "\r\n",
        "  # process each chunk\r\n",
        "  for chunk in chunks:\r\n",
        "\r\n",
        "    # add 0.5 sec silence to beginning and \r\n",
        "    # end of audio chunk. This is done so that\r\n",
        "    # it doesn't seem abruptly sliced.\r\n",
        "    audio_chunk = chunk_silent + chunk + chunk_silent\r\n",
        "\r\n",
        "    # Normalize the entire chunk.\r\n",
        "    normalized_chunk = match_target_amplitude(audio_chunk, -20.0)\r\n",
        "\r\n",
        "    print(\"saving chunk{0}.wav\".format(i))\r\n",
        "    normalized_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\")\r\n",
        "    i += 1\r\n",
        "  \r\n",
        "  os.chdir('..')\r\n",
        "  return i\r\n",
        "\r\n",
        "total_chunks = silence_based_conversion(path)"
      ],
      "outputs": [],
      "metadata": {
        "id": "3Z98nFBh9HIY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# load pretrained model\r\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\r\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "OXomWMufpr1V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "os.chdir(os.path.join(dir, 'audio_chunks'))\r\n",
        "\r\n",
        "text = ''\r\n",
        "\r\n",
        "for i in range(total_chunks):\r\n",
        "  audio, _ = librosa.load(\"chunk{0}.wav\".format(i), sr = sample_rate)\r\n",
        "  input_values = processor(audio, sampling_rate=sample_rate, return_tensors = \"pt\").input_values\r\n",
        "\r\n",
        "  # Storing logits (non-normalized prediction values)\r\n",
        "  logits = model(input_values).logits\r\n",
        "\r\n",
        "  # Storing predicted ids\r\n",
        "  prediction = torch.argmax(logits, dim = -1)\r\n",
        "\r\n",
        "  # Passing the prediction to the tokenzer decode to get the transcription\r\n",
        "  transcription = processor.batch_decode(prediction)[0]\r\n",
        "\r\n",
        "  text += transcription + '\\n'\r\n",
        "  print('chunk{0} processed'.format(i))\r\n",
        "\r\n",
        "os.chdir('..')"
      ],
      "outputs": [],
      "metadata": {
        "id": "H4wavcdkBldM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(text)"
      ],
      "outputs": [],
      "metadata": {
        "id": "T3rMP2jz8Wah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "file = open(r\"text.txt\",\"w+\")\r\n",
        "file.write(text)\r\n",
        "file.close()"
      ],
      "outputs": [],
      "metadata": {
        "id": "zxDc6MuSJiYs"
      }
    }
  ]
}